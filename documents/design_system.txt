1. Kiến trúc tổng quan
    Tại sao lại chia thành các mô-đun như này ?
        Chia dựa theo luồng xử lý của một hệ thống dữ liệu lớn
        Phân hóa từng chức năng riêng biệt của hệ thống để dễ dàng triển khai, kiểm soát

    Giải thích luồng dữ liệu ?
    
2. Thu thập dữ liệu
    Trình bày quá trình giả lập dữ liệu. Tại sao lại giả lập như vậy ?
        Phát triển theo hướng dữ liệu gửi liên tục không định kỳ nữa.
        Vẫn tập trung vào lấy dữ liệu định kỳ. Gọi API. Bật Spark Streaming 24h.

    Tại sao lại phải chèn Kafka vào ?
        Tạo một luồng streaming
        Tách biệt chức năng của Kafka và Spark streaming
        Tăng khả năng lưu trữ của hệ thống
        Spark Streaming không sợ dữ liệu đến muộn

    Flask
    Kafka, Zookeeper
    Spark Streaming
    Airflow

3. Lập lịch tác vụ

4. Lưu trữ dữ liệu

5. Xử lý dữ liệu

6. Truy vấn dữ liệu

7. Trực quan hóa dữ liệu

